{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 16)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#csv파일을 읽어와서 npy로 변환 / 데이터셋 생성과정에서 npy로 변환하여 저장하는 것이 좋을듯\n",
    "e_data = pd.read_csv('./dataset/e_fdata.csv', header=None)\n",
    "i_data = pd.read_csv('./dataset/i_fdata.csv', header=None)\n",
    "l_data = pd.read_csv('./dataset/l_fdata.csv', header=None)\n",
    "o_data = pd.read_csv('./dataset/o_fdata.csv', header=None)\n",
    "u_data = pd.read_csv('./dataset/u_fdata.csv', header=None)\n",
    "v_data = pd.read_csv('./dataset/v_fdata.csv', header=None)\n",
    "y_data = pd.read_csv('./dataset/y_fdata.csv', header=None)\n",
    "\n",
    "e_train_data = np.array(e_data)\n",
    "i_train_data = np.array(i_data)\n",
    "l_train_data = np.array(l_data)\n",
    "o_train_data = np.array(o_data)\n",
    "u_train_data = np.array(u_data)\n",
    "v_train_data = np.array(v_data)\n",
    "y_train_data = np.array(y_data)\n",
    "\n",
    "#csv파일을 npy로 변환하여 concatnate\n",
    "\n",
    "data = np.concatenate((e_train_data,\n",
    "                       i_train_data,\n",
    "                       l_train_data,\n",
    "                       o_train_data,\n",
    "                       u_train_data,\n",
    "                       v_train_data,\n",
    "                       y_train_data), axis=0)\n",
    "\n",
    "gesture = ['e', 'i', 'l', 'o', 'u', 'v', 'y']\n",
    "\n",
    "print(data.shape)\n",
    "print(len(gesture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 15)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:,:-1]\n",
    "labels = data[:,-1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 7)\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "y_data = enc.fit_transform(labels.reshape(-1,1)).toarray()\n",
    "\n",
    "print(y_data.shape)\n",
    "\n",
    "print(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 15) (280, 15)\n",
      "(1120, 7) (280, 7)\n",
      "[22.375252 15.498793  6.265651 35.45093  86.223366 33.085823 33.153336\n",
      " 95.4777   35.63967  28.647976 89.76065  36.83758  25.40758  68.49815\n",
      " 45.920403]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(x_data_train.shape, x_data_test.shape)\n",
    "print(y_data_train.shape, y_data_test.shape) \n",
    "print(x_data_train[0])\n",
    "print(y_data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857142857142858\n",
      "[[0. 0. 0. 0. 0. 1. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#KNN 모델 TEST\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "knn.fit(x_data_train, y_data_train)\n",
    "\n",
    "y_pred = knn.predict(x_data_test)\n",
    "\n",
    "y_pred1 = knn.predict([[20,36,22,13,2,3,7,4,3,20,150,9,33,138,9]]) #u\n",
    "\n",
    "y_pred2 = knn.predict([[25,40,11,10,2,1,8,2,5,21,150,12,5,160,7]]) #v\n",
    "\n",
    "print(knn.score(x_data_test, y_data_test))\n",
    "print(y_pred1)\n",
    "print(y_pred2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 64)                1024      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,335\n",
      "Trainable params: 3,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sequential Model TEST\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(15,), activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile( loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(x_data_train, y_data_train, epochs=200, batch_size=8)\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(x_data_test, y_data_test)\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# acc = history.history['accuracy']\n",
    "# epochs = range(1, len(loss)+1)\n",
    "\n",
    "# plt.plot(epochs, loss, 'r', label='Loss')\n",
    "# plt.plot(epochs, acc, 'g', label='Accuracy')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epochs')\n",
    "# plt.ylabel('loss/acc')\n",
    "# plt.show()\n",
    "\n",
    "# print(\"loss : \", test_loss)\n",
    "# print(\"acc : \", test_acc)\n",
    "\n",
    "# y_pred1 = model.predict([[20,36,22,13,2,3,7,4,3,20,150,9,33,138,9]]) #u\n",
    "\n",
    "# y_pred2 = model.predict([[25,40,11,10,2,1,8,2,5,21,150,12,5,160,7]]) #v\n",
    "\n",
    "# print(np.round(y_pred1)) #[[0. 0. 0. 0. 1. 0. 0.]]\n",
    "# print(np.round(y_pred2)) #[[0. 0. 0. 0. 0. 1. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      " 97/105 [==========================>...] - ETA: 0s - loss: 4.6692 - accuracy: 0.7204    \n",
      "Epoch 1: val_loss improved from inf to 0.23105, saving model to ./model/01model.hdf5\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 4.3353 - accuracy: 0.7369 - val_loss: 0.2310 - val_accuracy: 0.9321\n",
      "Epoch 2/2000\n",
      " 80/105 [=====================>........] - ETA: 0s - loss: 0.1730 - accuracy: 0.9312\n",
      "Epoch 2: val_loss improved from 0.23105 to 0.12772, saving model to ./model/02model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9286 - val_loss: 0.1277 - val_accuracy: 0.9321\n",
      "Epoch 3/2000\n",
      " 98/105 [===========================>..] - ETA: 0s - loss: 0.1213 - accuracy: 0.9528\n",
      "Epoch 3: val_loss improved from 0.12772 to 0.05661, saving model to ./model/03model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9548 - val_loss: 0.0566 - val_accuracy: 0.9821\n",
      "Epoch 4/2000\n",
      " 99/105 [===========================>..] - ETA: 0s - loss: 0.1071 - accuracy: 0.9482\n",
      "Epoch 4: val_loss did not improve from 0.05661\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9500 - val_loss: 0.0805 - val_accuracy: 0.9714\n",
      "Epoch 5/2000\n",
      " 54/105 [==============>...............] - ETA: 0s - loss: 0.0860 - accuracy: 0.9653\n",
      "Epoch 5: val_loss improved from 0.05661 to 0.04971, saving model to ./model/05model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9679 - val_loss: 0.0497 - val_accuracy: 0.9821\n",
      "Epoch 6/2000\n",
      "102/105 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9730\n",
      "Epoch 6: val_loss did not improve from 0.04971\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9714 - val_loss: 0.0592 - val_accuracy: 0.9786\n",
      "Epoch 7/2000\n",
      " 56/105 [===============>..............] - ETA: 0s - loss: 0.0787 - accuracy: 0.9710\n",
      "Epoch 7: val_loss did not improve from 0.04971\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9679 - val_loss: 0.1652 - val_accuracy: 0.9393\n",
      "Epoch 8/2000\n",
      " 58/105 [===============>..............] - ETA: 0s - loss: 0.0651 - accuracy: 0.9720    \n",
      "Epoch 8: val_loss improved from 0.04971 to 0.04449, saving model to ./model/08model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9631 - val_loss: 0.0445 - val_accuracy: 0.9857\n",
      "Epoch 9/2000\n",
      " 57/105 [===============>..............] - ETA: 0s - loss: 0.1227 - accuracy: 0.9539\n",
      "Epoch 9: val_loss did not improve from 0.04449\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.9357 - val_loss: 0.3316 - val_accuracy: 0.8929\n",
      "Epoch 10/2000\n",
      " 53/105 [==============>...............] - ETA: 0s - loss: 0.2655 - accuracy: 0.9222\n",
      "Epoch 10: val_loss improved from 0.04449 to 0.03887, saving model to ./model/10model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9333 - val_loss: 0.0389 - val_accuracy: 0.9857\n",
      "Epoch 11/2000\n",
      " 54/105 [==============>...............] - ETA: 0s - loss: 0.0879 - accuracy: 0.9653\n",
      "Epoch 11: val_loss did not improve from 0.03887\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9726 - val_loss: 0.0393 - val_accuracy: 0.9786\n",
      "Epoch 12/2000\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9750\n",
      "Epoch 12: val_loss did not improve from 0.03887\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9750 - val_loss: 0.0726 - val_accuracy: 0.9643\n",
      "Epoch 13/2000\n",
      " 89/105 [========================>.....] - ETA: 0s - loss: 0.0704 - accuracy: 0.9733\n",
      "Epoch 13: val_loss did not improve from 0.03887\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9702 - val_loss: 0.0451 - val_accuracy: 0.9857\n",
      "Epoch 14/2000\n",
      " 86/105 [=======================>......] - ETA: 0s - loss: 0.0651 - accuracy: 0.9738\n",
      "Epoch 14: val_loss did not improve from 0.03887\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9738 - val_loss: 0.1204 - val_accuracy: 0.9357\n",
      "Epoch 15/2000\n",
      " 97/105 [==========================>...] - ETA: 0s - loss: 0.0407 - accuracy: 0.9832\n",
      "Epoch 15: val_loss did not improve from 0.03887\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9845 - val_loss: 0.0470 - val_accuracy: 0.9857\n",
      "Epoch 16/2000\n",
      " 98/105 [===========================>..] - ETA: 0s - loss: 0.0515 - accuracy: 0.9770\n",
      "Epoch 16: val_loss did not improve from 0.03887\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9774 - val_loss: 0.1065 - val_accuracy: 0.9536\n",
      "Epoch 17/2000\n",
      " 84/105 [=======================>......] - ETA: 0s - loss: 0.0461 - accuracy: 0.9792\n",
      "Epoch 17: val_loss improved from 0.03887 to 0.03547, saving model to ./model/17model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9762 - val_loss: 0.0355 - val_accuracy: 0.9893\n",
      "Epoch 18/2000\n",
      " 86/105 [=======================>......] - ETA: 0s - loss: 0.0365 - accuracy: 0.9869\n",
      "Epoch 18: val_loss improved from 0.03547 to 0.02676, saving model to ./model/18model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9857 - val_loss: 0.0268 - val_accuracy: 0.9929\n",
      "Epoch 19/2000\n",
      " 93/105 [=========================>....] - ETA: 0s - loss: 0.0741 - accuracy: 0.9677\n",
      "Epoch 19: val_loss did not improve from 0.02676\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9714 - val_loss: 0.0451 - val_accuracy: 0.9786\n",
      "Epoch 20/2000\n",
      "102/105 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 0.9828\n",
      "Epoch 20: val_loss did not improve from 0.02676\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9821 - val_loss: 0.0512 - val_accuracy: 0.9786\n",
      "Epoch 21/2000\n",
      " 96/105 [==========================>...] - ETA: 0s - loss: 0.0427 - accuracy: 0.9857\n",
      "Epoch 21: val_loss improved from 0.02676 to 0.02296, saving model to ./model/21model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0230 - val_accuracy: 0.9893\n",
      "Epoch 22/2000\n",
      "103/105 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9830\n",
      "Epoch 22: val_loss improved from 0.02296 to 0.02250, saving model to ./model/22model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9833 - val_loss: 0.0225 - val_accuracy: 0.9964\n",
      "Epoch 23/2000\n",
      " 93/105 [=========================>....] - ETA: 0s - loss: 0.1304 - accuracy: 0.9556\n",
      "Epoch 23: val_loss improved from 0.02250 to 0.02193, saving model to ./model/23model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9571 - val_loss: 0.0219 - val_accuracy: 0.9929\n",
      "Epoch 24/2000\n",
      " 96/105 [==========================>...] - ETA: 0s - loss: 0.0400 - accuracy: 0.9792\n",
      "Epoch 24: val_loss did not improve from 0.02193\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9810 - val_loss: 0.0266 - val_accuracy: 0.9929\n",
      "Epoch 25/2000\n",
      " 95/105 [==========================>...] - ETA: 0s - loss: 0.0341 - accuracy: 0.9829  \n",
      "Epoch 25: val_loss did not improve from 0.02193\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9833 - val_loss: 0.0673 - val_accuracy: 0.9786\n",
      "Epoch 26/2000\n",
      "101/105 [===========================>..] - ETA: 0s - loss: 0.0328 - accuracy: 0.9864\n",
      "Epoch 26: val_loss did not improve from 0.02193\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9869 - val_loss: 0.0419 - val_accuracy: 0.9857\n",
      "Epoch 27/2000\n",
      "102/105 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9828  \n",
      "Epoch 27: val_loss improved from 0.02193 to 0.01706, saving model to ./model/27model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9833 - val_loss: 0.0171 - val_accuracy: 0.9929\n",
      "Epoch 28/2000\n",
      " 94/105 [=========================>....] - ETA: 0s - loss: 0.0406 - accuracy: 0.9840\n",
      "Epoch 28: val_loss did not improve from 0.01706\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9857 - val_loss: 0.0244 - val_accuracy: 0.9893\n",
      "Epoch 29/2000\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9940\n",
      "Epoch 29: val_loss did not improve from 0.01706\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.1593 - val_accuracy: 0.9179\n",
      "Epoch 30/2000\n",
      " 84/105 [=======================>......] - ETA: 0s - loss: 0.0398 - accuracy: 0.9836  \n",
      "Epoch 30: val_loss did not improve from 0.01706\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9810 - val_loss: 0.0182 - val_accuracy: 0.9893\n",
      "Epoch 31/2000\n",
      " 84/105 [=======================>......] - ETA: 0s - loss: 0.0294 - accuracy: 0.9896\n",
      "Epoch 31: val_loss did not improve from 0.01706\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9869 - val_loss: 0.0351 - val_accuracy: 0.9893\n",
      "Epoch 32/2000\n",
      " 63/105 [=================>............] - ETA: 0s - loss: 0.0811 - accuracy: 0.9583\n",
      "Epoch 32: val_loss did not improve from 0.01706\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9595 - val_loss: 0.0640 - val_accuracy: 0.9750\n",
      "Epoch 33/2000\n",
      " 99/105 [===========================>..] - ETA: 0s - loss: 0.0418 - accuracy: 0.9811  \n",
      "Epoch 33: val_loss did not improve from 0.01706\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9821 - val_loss: 0.0334 - val_accuracy: 0.9821\n",
      "Epoch 34/2000\n",
      " 96/105 [==========================>...] - ETA: 0s - loss: 0.0223 - accuracy: 0.9909\n",
      "Epoch 34: val_loss improved from 0.01706 to 0.01633, saving model to ./model/34model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9905 - val_loss: 0.0163 - val_accuracy: 0.9929\n",
      "Epoch 35/2000\n",
      " 84/105 [=======================>......] - ETA: 0s - loss: 0.0476 - accuracy: 0.9851  \n",
      "Epoch 35: val_loss did not improve from 0.01633\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.0296 - val_accuracy: 0.9929\n",
      "Epoch 36/2000\n",
      "102/105 [============================>.] - ETA: 0s - loss: 0.0443 - accuracy: 0.9816  \n",
      "Epoch 36: val_loss did not improve from 0.01633\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9821 - val_loss: 0.1363 - val_accuracy: 0.9464\n",
      "Epoch 37/2000\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9760\n",
      "Epoch 37: val_loss did not improve from 0.01633\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9762 - val_loss: 0.0567 - val_accuracy: 0.9786\n",
      "Epoch 38/2000\n",
      " 90/105 [========================>.....] - ETA: 0s - loss: 0.0176 - accuracy: 0.9931\n",
      "Epoch 38: val_loss did not improve from 0.01633\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9917 - val_loss: 0.0177 - val_accuracy: 0.9893\n",
      "Epoch 39/2000\n",
      " 96/105 [==========================>...] - ETA: 0s - loss: 0.0159 - accuracy: 0.9935  \n",
      "Epoch 39: val_loss did not improve from 0.01633\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 0.0194 - val_accuracy: 0.9964\n",
      "Epoch 40/2000\n",
      "101/105 [===========================>..] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000  \n",
      "Epoch 40: val_loss did not improve from 0.01633\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.0224 - val_accuracy: 0.9964\n",
      "Epoch 41/2000\n",
      "101/105 [===========================>..] - ETA: 0s - loss: 0.0273 - accuracy: 0.9913  \n",
      "Epoch 41: val_loss did not improve from 0.01633\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 0.0209 - val_accuracy: 0.9929\n",
      "Epoch 42/2000\n",
      " 95/105 [==========================>...] - ETA: 0s - loss: 0.0152 - accuracy: 0.9961\n",
      "Epoch 42: val_loss did not improve from 0.01633\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0359 - val_accuracy: 0.9821\n",
      "Epoch 43/2000\n",
      " 53/105 [==============>...............] - ETA: 0s - loss: 0.0178 - accuracy: 0.9929\n",
      "Epoch 43: val_loss improved from 0.01633 to 0.01500, saving model to ./model/43model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9917 - val_loss: 0.0150 - val_accuracy: 0.9929\n",
      "Epoch 44/2000\n",
      " 94/105 [=========================>....] - ETA: 0s - loss: 0.0476 - accuracy: 0.9854\n",
      "Epoch 44: val_loss did not improve from 0.01500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9845 - val_loss: 0.0190 - val_accuracy: 0.9929\n",
      "Epoch 45/2000\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9892  \n",
      "Epoch 45: val_loss did not improve from 0.01500\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.0229 - val_accuracy: 0.9929\n",
      "Epoch 46/2000\n",
      " 99/105 [===========================>..] - ETA: 0s - loss: 0.0132 - accuracy: 0.9937  \n",
      "Epoch 46: val_loss improved from 0.01500 to 0.01275, saving model to ./model/46model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.9940 - val_loss: 0.0127 - val_accuracy: 0.9929\n",
      "Epoch 47/2000\n",
      " 88/105 [========================>.....] - ETA: 0s - loss: 0.0103 - accuracy: 0.9957\n",
      "Epoch 47: val_loss improved from 0.01275 to 0.01243, saving model to ./model/47model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9952 - val_loss: 0.0124 - val_accuracy: 0.9929\n",
      "Epoch 48/2000\n",
      " 96/105 [==========================>...] - ETA: 0s - loss: 0.0060 - accuracy: 0.9987\n",
      "Epoch 48: val_loss did not improve from 0.01243\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0162 - val_accuracy: 0.9929\n",
      "Epoch 49/2000\n",
      " 95/105 [==========================>...] - ETA: 0s - loss: 0.0763 - accuracy: 0.9776  \n",
      "Epoch 49: val_loss did not improve from 0.01243\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9786 - val_loss: 0.0249 - val_accuracy: 0.9964\n",
      "Epoch 50/2000\n",
      " 91/105 [=========================>....] - ETA: 0s - loss: 0.0191 - accuracy: 0.9931  \n",
      "Epoch 50: val_loss did not improve from 0.01243\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 0.0290 - val_accuracy: 0.9893\n",
      "Epoch 51/2000\n",
      " 98/105 [===========================>..] - ETA: 0s - loss: 0.0095 - accuracy: 0.9974\n",
      "Epoch 51: val_loss improved from 0.01243 to 0.00964, saving model to ./model/51model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.0096 - val_accuracy: 0.9964\n",
      "Epoch 52/2000\n",
      " 94/105 [=========================>....] - ETA: 0s - loss: 0.0123 - accuracy: 0.9960  \n",
      "Epoch 52: val_loss improved from 0.00964 to 0.00808, saving model to ./model/52model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9952 - val_loss: 0.0081 - val_accuracy: 0.9964\n",
      "Epoch 53/2000\n",
      " 90/105 [========================>.....] - ETA: 0s - loss: 0.0138 - accuracy: 0.9958  \n",
      "Epoch 53: val_loss did not improve from 0.00808\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0158 - val_accuracy: 0.9964\n",
      "Epoch 54/2000\n",
      "102/105 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9767  \n",
      "Epoch 54: val_loss did not improve from 0.00808\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9774 - val_loss: 0.0147 - val_accuracy: 0.9893\n",
      "Epoch 55/2000\n",
      " 93/105 [=========================>....] - ETA: 0s - loss: 0.0123 - accuracy: 0.9960\n",
      "Epoch 55: val_loss did not improve from 0.00808\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9952 - val_loss: 0.0590 - val_accuracy: 0.9714\n",
      "Epoch 56/2000\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9964\n",
      "Epoch 56: val_loss did not improve from 0.00808\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0490 - val_accuracy: 0.9786\n",
      "Epoch 57/2000\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9892  \n",
      "Epoch 57: val_loss did not improve from 0.00808\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9893 - val_loss: 0.0175 - val_accuracy: 0.9929\n",
      "Epoch 58/2000\n",
      " 99/105 [===========================>..] - ETA: 0s - loss: 0.0259 - accuracy: 0.9912  \n",
      "Epoch 58: val_loss did not improve from 0.00808\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0160 - val_accuracy: 0.9964\n",
      "Epoch 59/2000\n",
      " 97/105 [==========================>...] - ETA: 0s - loss: 0.0070 - accuracy: 0.9987  \n",
      "Epoch 59: val_loss improved from 0.00808 to 0.00559, saving model to ./model/59model.hdf5\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      " 98/105 [===========================>..] - ETA: 0s - loss: 0.0165 - accuracy: 0.9898\n",
      "Epoch 60: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9905 - val_loss: 0.0072 - val_accuracy: 0.9964\n",
      "Epoch 61/2000\n",
      " 99/105 [===========================>..] - ETA: 0s - loss: 0.0117 - accuracy: 0.9924\n",
      "Epoch 61: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9905 - val_loss: 0.0212 - val_accuracy: 0.9929\n",
      "Epoch 62/2000\n",
      " 95/105 [==========================>...] - ETA: 0s - loss: 0.0331 - accuracy: 0.9868\n",
      "Epoch 62: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0080 - val_accuracy: 0.9964\n",
      "Epoch 63/2000\n",
      " 92/105 [=========================>....] - ETA: 0s - loss: 0.0096 - accuracy: 0.9932  \n",
      "Epoch 63: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9940 - val_loss: 0.0160 - val_accuracy: 0.9964\n",
      "Epoch 64/2000\n",
      " 99/105 [===========================>..] - ETA: 0s - loss: 0.0590 - accuracy: 0.9798  \n",
      "Epoch 64: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9798 - val_loss: 0.0155 - val_accuracy: 0.9964\n",
      "Epoch 65/2000\n",
      " 96/105 [==========================>...] - ETA: 0s - loss: 0.0136 - accuracy: 0.9974\n",
      "Epoch 65: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.0085 - val_accuracy: 0.9964\n",
      "Epoch 66/2000\n",
      " 97/105 [==========================>...] - ETA: 0s - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 66: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0110 - val_accuracy: 0.9929\n",
      "Epoch 67/2000\n",
      " 97/105 [==========================>...] - ETA: 0s - loss: 0.0065 - accuracy: 0.9987\n",
      "Epoch 67: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0117 - val_accuracy: 0.9929\n",
      "Epoch 68/2000\n",
      " 86/105 [=======================>......] - ETA: 0s - loss: 0.0105 - accuracy: 0.9971  \n",
      "Epoch 68: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0154 - val_accuracy: 0.9929\n",
      "Epoch 69/2000\n",
      "100/105 [===========================>..] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 69: val_loss did not improve from 0.00559\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9893\n",
      "9/9 [==============================] - 0s 983us/step - loss: 0.0026 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.002575381426140666\n",
      "acc :  1.0\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe9a91e1e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[0. 0. 0. 0. 1. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}model.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(x_data_train, y_data_train, validation_split=0.25, epochs=2000, batch_size=8,\n",
    "                    verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_data_test, y_data_test)\n",
    "\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Loss')\n",
    "plt.plot(epochs, acc, 'g', label='Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss/acc')\n",
    "plt.show()\n",
    "\n",
    "print(\"loss : \", test_loss)\n",
    "print(\"acc : \", test_acc)\n",
    "\n",
    "y_pred1 = model.predict([[20,36,22,13,2,3,7,4,3,20,150,9,33,138,9]]) #u\n",
    "\n",
    "y_pred2 = model.predict([[25,40,11,10,2,1,8,2,5,21,150,12,5,160,7]]) #v\n",
    "\n",
    "print(np.round(y_pred1)) #[[0. 0. 0. 0. 1. 0. 0.]]\n",
    "print(np.round(y_pred2)) #[[0. 0. 0. 0. 0. 1. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdel\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
