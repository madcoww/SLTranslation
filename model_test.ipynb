{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 16)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#csv파일을 읽어와서 npy로 변환 / 데이터셋 생성과정에서 npy로 변환하여 저장하는 것이 좋을듯\n",
    "e_data = pd.read_csv('./dataset/e_fdata.csv', header=None)\n",
    "i_data = pd.read_csv('./dataset/i_fdata.csv', header=None)\n",
    "l_data = pd.read_csv('./dataset/l_fdata.csv', header=None)\n",
    "o_data = pd.read_csv('./dataset/o_fdata.csv', header=None)\n",
    "u_data = pd.read_csv('./dataset/u_fdata.csv', header=None)\n",
    "v_data = pd.read_csv('./dataset/v_fdata.csv', header=None)\n",
    "y_data = pd.read_csv('./dataset/y_fdata.csv', header=None)\n",
    "\n",
    "e_train_data = np.array(e_data)\n",
    "i_train_data = np.array(i_data)\n",
    "l_train_data = np.array(l_data)\n",
    "o_train_data = np.array(o_data)\n",
    "u_train_data = np.array(u_data)\n",
    "v_train_data = np.array(v_data)\n",
    "y_train_data = np.array(y_data)\n",
    "\n",
    "#csv파일을 npy로 변환하여 concatnate\n",
    "\n",
    "data = np.concatenate((e_train_data,\n",
    "                       i_train_data,\n",
    "                       l_train_data,\n",
    "                       o_train_data,\n",
    "                       u_train_data,\n",
    "                       v_train_data,\n",
    "                       y_train_data), axis=0)\n",
    "\n",
    "gesture = ['e', 'i', 'l', 'o', 'u', 'v', 'y']\n",
    "\n",
    "print(data.shape)\n",
    "print(len(gesture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 15)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:,:-1]\n",
    "labels = data[:,-1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 7)\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "y_data = enc.fit_transform(labels.reshape(-1,1)).toarray()\n",
    "\n",
    "print(y_data.shape)\n",
    "\n",
    "print(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 15) (280, 15)\n",
      "(1120, 7) (280, 7)\n",
      "[22.375252 15.498793  6.265651 35.45093  86.223366 33.085823 33.153336\n",
      " 95.4777   35.63967  28.647976 89.76065  36.83758  25.40758  68.49815\n",
      " 45.920403]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(x_data_train.shape, x_data_test.shape)\n",
    "print(y_data_train.shape, y_data_test.shape) \n",
    "print(x_data_train[0])\n",
    "print(y_data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857142857142858\n",
      "[[0. 0. 0. 0. 0. 1. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#KNN 모델 TEST\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "knn.fit(x_data_train, y_data_train)\n",
    "\n",
    "y_pred = knn.predict(x_data_test)\n",
    "\n",
    "y_pred1 = knn.predict([[20,36,22,13,2,3,7,4,3,20,150,9,33,138,9]]) #u\n",
    "\n",
    "y_pred2 = knn.predict([[25,40,11,10,2,1,8,2,5,21,150,12,5,160,7]]) #v\n",
    "\n",
    "print(knn.score(x_data_test, y_data_test))\n",
    "print(y_pred1)\n",
    "print(y_pred2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 19:13:29.522403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-13 19:13:36.100470: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1024      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,335\n",
      "Trainable params: 3,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sequential Model TEST\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(15,), activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile( loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(x_data_train, y_data_train, epochs=200, batch_size=8)\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(x_data_test, y_data_test)\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# acc = history.history['accuracy']\n",
    "# epochs = range(1, len(loss)+1)\n",
    "\n",
    "# plt.plot(epochs, loss, 'r', label='Loss')\n",
    "# plt.plot(epochs, acc, 'g', label='Accuracy')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epochs')\n",
    "# plt.ylabel('loss/acc')\n",
    "# plt.show()\n",
    "\n",
    "# print(\"loss : \", test_loss)\n",
    "# print(\"acc : \", test_acc)\n",
    "\n",
    "# y_pred1 = model.predict([[20,36,22,13,2,3,7,4,3,20,150,9,33,138,9]]) #u\n",
    "\n",
    "# y_pred2 = model.predict([[25,40,11,10,2,1,8,2,5,21,150,12,5,160,7]]) #v\n",
    "\n",
    "# print(np.round(y_pred1)) #[[0. 0. 0. 0. 1. 0. 0.]]\n",
    "# print(np.round(y_pred2)) #[[0. 0. 0. 0. 0. 1. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 19:29:20.832483: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m modelpath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./model/\u001b[39m\u001b[39m{epoch:02d}\u001b[39;00m\u001b[39mmodel.hdf5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m checkpointer \u001b[39m=\u001b[39m ModelCheckpoint(filepath\u001b[39m=\u001b[39mmodelpath, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(x_data_train, y_data_train, validation_split\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,\n\u001b[1;32m     10\u001b[0m                     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, callbacks\u001b[39m=\u001b[39m[early_stopping_callback, checkpointer])\n\u001b[1;32m     12\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_data_test, y_data_test)\n\u001b[1;32m     14\u001b[0m loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}model.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(x_data_train, y_data_train, validation_split=0.25, epochs=10000, batch_size=8,\n",
    "                    verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_data_test, y_data_test)\n",
    "\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Loss')\n",
    "plt.plot(epochs, acc, 'g', label='Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss/acc')\n",
    "plt.show()\n",
    "\n",
    "print(\"loss : \", test_loss)\n",
    "print(\"acc : \", test_acc)\n",
    "\n",
    "y_pred1 = model.predict([[20,36,22,13,2,3,7,4,3,20,150,9,33,138,9]]) #u\n",
    "\n",
    "y_pred2 = model.predict([[25,40,11,10,2,1,8,2,5,21,150,12,5,160,7]]) #v\n",
    "\n",
    "print(np.round(y_pred1)) #[[0. 0. 0. 0. 1. 0. 0.]]\n",
    "print(np.round(y_pred2)) #[[0. 0. 0. 0. 0. 1. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
